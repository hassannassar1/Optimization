# Optimization
It's about optimization techniques like Adam, Adagrad, RMSProp, Momentum, NAG and Gradients.
